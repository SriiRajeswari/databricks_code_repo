{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f66f4d89-114b-4182-b526-cbcf139759be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da8c3a64-b010-453f-9546-fb538cd60a1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DateType, BooleanType\n",
    "from pyspark.sql.functions import col, count, sum, avg, max, min, countDistinct, mean, stddev, stddev_pop, skewness, kurtosis, corr, covar_pop, covar_samp, approx_count_distinct, collect_list, collect_set, first, last, array_contains, array_sort, array_agg, array_distinct, array_except, array_intersect, array_remove, array_union,arrays_overlap, row_number, dense_rank, rank, lag, lead, window\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1281d4ac-b9a8-4a93-aa12-e424eb65d6a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#create session\n",
    "spark = SparkSession.builder.appName(\"IPL Data Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662c55de-b391-457a-a796-d22cc06996a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94785846-d99e-4f0e-8f94-dcd6a22aa945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_schema=StructType([StructField(\"MatcH_id\",IntegerType(),True),\n",
    "                                StructField(\"Over_id\",IntegerType(),True),\n",
    "                                StructField(\"Ball_id\",IntegerType(),True),\n",
    "                                StructField(\"Innings_No\",IntegerType(),True),\n",
    "                                StructField(\"Team_Batting\",StringType(),True),\n",
    "                                StructField(\"Team_Bowling\",StringType(),True),\n",
    "                                StructField(\"Batsman\",StringType(),True),\n",
    "                                StructField(\"Bowler\",StringType(),True),\n",
    "                                StructField(\"Striker_Batting_Position\",IntegerType(),True),\n",
    "                                StructField(\"Extra_Type\",StringType(),True),\n",
    "                                StructField(\"Runs_Scored\",IntegerType(),True),\n",
    "                                StructField(\"Extra_runs\",IntegerType(),True),\n",
    "                                StructField(\"Wides\",IntegerType(),True),\n",
    "                                StructField(\"Legbyes\",IntegerType(),True),\n",
    "                                StructField(\"Byes\",IntegerType(),True),\n",
    "                                StructField(\"Noballs\",IntegerType(),True),\n",
    "                                StructField(\"Penalty\",IntegerType(),True),\n",
    "                                StructField(\"Wicket_Type\",StringType(),True),\n",
    "                                StructField(\"Caught\",BooleanType(),True),\n",
    "                                StructField(\"Bowled\",BooleanType(),True),\n",
    "                                StructField(\"Run_out\",BooleanType(),True),\n",
    "                                StructField(\"Hit_wicket\",IntegerType(),True),\n",
    "                                StructField(\"Stumped\",IntegerType(),True),\n",
    "                                StructField(\"Fielder\",StringType(),True),\n",
    "                                StructField(\"Caught_and_bowled\",IntegerType(),True),\n",
    "                                StructField(\"LBW\",BooleanType(),True),\n",
    "                                StructField(\"Retired_hurt\",BooleanType(),True),\n",
    "                                StructField(\"ObstructingFeild\",IntegerType(),True),\n",
    "                                StructField(\"Bowler_Wicket\",IntegerType(),True),\n",
    "                                StructField(\"Match_Date\",DateType(),True),\n",
    "                                StructField(\"Season\",IntegerType(),True),\n",
    "                                StructField(\"Striker\",IntegerType(),True),\n",
    "                                StructField(\"Non_Striker\",IntegerType(),True),\n",
    "                                StructField(\"Player_Out\",IntegerType(),True),\n",
    "                                StructField(\"Fielders\",IntegerType(),True),\n",
    "                                StructField(\"Striker_match_SK\",IntegerType(),True),\n",
    "                                StructField(\"StrikerSK\",IntegerType(),True),\n",
    "                                StructField(\"NonStriker_match_SK\",IntegerType(),True),\n",
    "                                StructField(\"NONStriker_SK\",IntegerType(),True),\n",
    "                                StructField(\"Fielder_match_SK\",IntegerType(),True),\n",
    "                                StructField(\"Fielder_SK\",IntegerType(),True),\n",
    "                                StructField(\"Bowler_match_SK\",IntegerType(),True),\n",
    "                                StructField(\"BOWLER_SK\",IntegerType(),True),\n",
    "                                StructField(\"PlayerOut_match_SK\",IntegerType(),True),\n",
    "                                StructField(\"BattingTeam_SK\",IntegerType(),True),\n",
    "                                StructField(\"BowlingTeam_SK\",IntegerType(),True),\n",
    "                                StructField(\"Keeper_Catch\",IntegerType(),True),\n",
    "                                StructField(\"Player_out_sk\",IntegerType(),True),\n",
    "                                StructField(\"MatchDateSK\",IntegerType(),True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca4e3c14-90f0-4ccf-b484-e78cceeb262b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df = spark.read.schema(ball_by_ball_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Ball_By_Ball.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c63dc30-2a35-4bca-ba4f-2b9ad00ed388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "match_schema = StructType([\n",
    "    StructField(\"Match_id\", IntegerType(), True),\n",
    "    StructField(\"Team1\", StringType(), True),\n",
    "    StructField(\"Team2\", StringType(), True),\n",
    "    StructField(\"Team1_SK\", IntegerType(), True),\n",
    "    StructField(\"Team2_SK\", IntegerType(), True),\n",
    "    StructField(\"Winner\", StringType(), True),\n",
    "    StructField(\"Winner_SK\", IntegerType(), True),\n",
    "    StructField(\"Tournament\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Venue\", StringType(), True),\n",
    "    StructField(\"Venue_SK\", IntegerType(), True),\n",
    "    StructField(\"Match_Date\", DateType(), True),\n",
    "    StructField(\"Season\", IntegerType(), True),\n",
    "    StructField(\"MatchDateSK\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "match_df = spark.read.schema(match_schema).format(\"csv\").option(\n",
    "    \"header\", \"true\"\n",
    ").load(\"s3://ipl-data-analysis-project/Match.csv\")\n",
    "\n",
    "display(match_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6db5e5e-2ec4-466d-a308-fc31934f8c0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_match_schema=StructType([\n",
    "    StructField(\"Player_SK\",IntegerType(),True),\n",
    "    StructField(\"Player_Name\",StringType(),True),\n",
    "    StructField(\"Team_SK\",IntegerType(),True),\n",
    "    StructField(\"Team_Name\",StringType(),True),\n",
    "    StructField(\"Player_Match_SK\",IntegerType(),True)\n",
    "])\n",
    "player_match_df=spark.read.schema(player_match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player_Match.csv\")\n",
    "player_schema=StructType([\n",
    "    StructField(\"Player_SK\",IntegerType(),True),\n",
    "    StructField(\"Player_Name\",StringType(),True)\n",
    "])\n",
    "player_df=spark.read.schema(player_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef9d8d45-1be9-4cbd-bcb6-0268c689323d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "team_schema=StructType([\n",
    "    StructField(\"Team_SK\",IntegerType(),True),\n",
    "    StructField(\"Team_Name\",StringType(),True),\n",
    "    StructField(\"Team_Match_SK\",IntegerType(),True)\n",
    "])\n",
    "team_df=spark.read.schema(team_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Team.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c84b2cb-645a-4f97-b377-2f70985426b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#filter to include only valid deliveries (exclude wides and no balls)\n",
    "from pyspark.sql.functions import col\n",
    "ball_by_ball_df = ball_by_ball_df.filter((col(\"Wides\") == 0) & (col(\"Noballs\") == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0c4afb4-2047-4912-85c6-0089bf89e7fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#agg:calculate the total and avg runs scored in each match and inning\n",
    "total_and_avg_runs = ball_by_ball_df.groupBy(\"MatcH_id\", \"Innings_No\").agg(\n",
    "    sum(\"Runs_Scored\").alias(\"total_runs\"),\n",
    "    avg(\"Runs_Scored\").alias(\"avg_runs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567330cb-1def-4259-913c-6ffe8e764d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#window function:calculate running total of runs in each match for each over\n",
    "windowSpec = Window.partitionBy(\"MatcH_id\").orderBy(\"Over_id\")\n",
    "#to add new column\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\"running_total\", sum(\"Runs_Scored\").over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aeaa0a5-c7d0-413c-86d1-1afaa6209864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#conditional column:flag for high impact balls(either a wicket or more than 6 runs including extras)\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\n",
    "    \"High_Impact_Ball\",\n",
    "    when(\n",
    "        (col(\"Runs_Scored\") + col(\"Extra_runs\") > 6) | (col(\"Bowler_Wicket\") == 1),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cce8f896-f90a-487c-8b78-6282f6eb4c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    to_date,\n",
    "    year,\n",
    "    month,\n",
    "    dayofmonth,\n",
    "    when,\n",
    "    col\n",
    ")\n",
    "\n",
    "match_df = spark.read.format(\"csv\").option(\"header\", True).load(\n",
    "    \"s3://ipl-data-analysis-project/Match.csv\"\n",
    ")\n",
    "\n",
    "# Parse Match_Date using try_to_date to handle malformed values\n",
    "match_df = match_df.withColumn(\n",
    "    \"Match_Date_Parsed\",\n",
    "    to_date(col(\"Match_Date\"), \"M/d/yyyy\")\n",
    ")\n",
    "\n",
    "match_df = match_df.withColumn(\n",
    "    \"Year\",\n",
    "    year(col(\"Match_Date_Parsed\"))\n",
    ")\n",
    "match_df = match_df.withColumn(\n",
    "    \"Month\",\n",
    "    month(col(\"Match_Date_Parsed\"))\n",
    ")\n",
    "match_df = match_df.withColumn(\n",
    "    \"Day\",\n",
    "    dayofmonth(col(\"Match_Date_Parsed\"))\n",
    ")\n",
    "\n",
    "match_df = match_df.withColumn(\n",
    "    \"Win_Margin\",\n",
    "    when(\n",
    "        col(\"Win_Type\") == \"Runs\",\n",
    "        \"High\"\n",
    "    ).when(\n",
    "        col(\"Win_Type\") == \"Wickets\",\n",
    "        \"Medium\"\n",
    "    ).otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "match_df = match_df.withColumn(\n",
    "    \"Toss_Winner_Impact\",\n",
    "    when(\n",
    "        col(\"Toss_Winner\") == col(\"Team1\"),\n",
    "        \"Yes\"\n",
    "    ).otherwise(\"No\")\n",
    ")\n",
    "\n",
    "display(match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "704bc7be-0229-4bc2-8461-f7aec316081b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    to_date,\n",
    "    year,\n",
    "    month,\n",
    "    dayofmonth,\n",
    "    when,\n",
    "    col,\n",
    "    expr\n",
    ")\n",
    "\n",
    "# Parse Match_Date to date type using the correct format\n",
    "match_df = match_df.withColumn(\n",
    "    \"Match_Date_Parsed\",\n",
    "    to_date(col(\"Match_Date\"), \"M/d/yyyy\")\n",
    ")\n",
    "\n",
    "# Extract year, month, and day from the parsed date\n",
    "match_df = match_df.withColumn(\n",
    "    \"Year\",\n",
    "    year(col(\"Match_Date_Parsed\"))\n",
    ")\n",
    "match_df = match_df.withColumn(\n",
    "    \"Month\",\n",
    "    month(col(\"Match_Date_Parsed\"))\n",
    ")\n",
    "match_df = match_df.withColumn(\n",
    "    \"Day\",\n",
    "    dayofmonth(col(\"Match_Date_Parsed\"))\n",
    ")\n",
    "\n",
    "# Cast Win_margin to integer safely using try_cast\n",
    "match_df = match_df.withColumn(\n",
    "    \"Win_margin_int\",\n",
    "    expr(\"try_cast(Win_margin as int)\")\n",
    ")\n",
    "\n",
    "# Categorize Win_margin_int into High, Medium, Low\n",
    "match_df = match_df.withColumn(\n",
    "    \"Win_Margin_Category\",\n",
    "    when(\n",
    "        col(\"Win_margin_int\") >= 100,\n",
    "        \"High\"\n",
    "    ).when(\n",
    "        (col(\"Win_margin_int\") >= 50) & (col(\"Win_margin_int\") < 100),\n",
    "        \"Medium\"\n",
    "    ).otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "# Analyze the impact of the toss\n",
    "match_df = match_df.withColumn(\n",
    "    \"Toss_Winner_Impact\",\n",
    "    when(\n",
    "        col(\"Toss_Winner\") == col(\"match_winner\"),\n",
    "        \"Yes\"\n",
    "    ).otherwise(\"No\")\n",
    ")\n",
    "\n",
    "display(match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f372c3-879a-4f0a-bc83-85880bd42504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the player data from a CSV file\n",
    "player_df = spark.read.format(\"csv\").option(\"header\", True).load(\"s3://ipl-data-analysis-project/Player.csv\")\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    lower,\n",
    "    regexp_replace,\n",
    "    col,\n",
    "    when\n",
    ")\n",
    "\n",
    "# Normalize and clean player names\n",
    "player_df = player_df.withColumn(\n",
    "    \"Player_Name\",\n",
    "    lower(\n",
    "        regexp_replace(\n",
    "            col(\"Player_Name\"),\n",
    "            \"[^a-zA-Z ]\",\n",
    "            \"\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Handle missing values in 'batting_hand' and 'bowling_skill' with default 'unknown'\n",
    "player_df = player_df.fillna(\n",
    "    {\n",
    "        \"batting_hand\": \"unknown\",\n",
    "        \"bowling_skill\": \"unknown\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Categorize players based on batting hand\n",
    "player_df = player_df.withColumn(\n",
    "    \"Batting_Style\",\n",
    "    when(\n",
    "        col(\"batting_hand\").contains(\"left\"),\n",
    "        \"Left-Handed\"\n",
    "    ).otherwise(\"Right-Handed\")\n",
    ")\n",
    "\n",
    "display(player_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edcaa6c8-234e-44c6-9f1c-2553c1eafc0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, current_date, expr, year\n",
    "\n",
    "# Example: Use 'Player_Id' as a placeholder for age_as_on_match logic\n",
    "# Replace 'Player_Id' with the correct column if you have an age column\n",
    "player_match_df = player_df.withColumn(\n",
    "    \"veteran_status\",\n",
    "    when(col(\"Player_Id\") >= 35, \"veteran\").otherwise(\"non-veteran\")\n",
    ")\n",
    "\n",
    "# If 'season_year' does not exist, replace it with the correct year column\n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"years_since_debut\",\n",
    "    year(current_date()) - col(\"Player_Id\")\n",
    ")\n",
    "\n",
    "display(player_match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202012cd-10e9-49ef-ba90-411ad1a76f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_df = spark.read.table(\"player\")\n",
    "player_match_df = spark.read.table(\"player_match\")\n",
    "ball_by_ball_df = spark.read.table(\"ball_by_ball\")\n",
    "team_df = spark.read.table(\"team\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07319d1f-3b95-4047-b448-89ba7880c43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load match data\n",
    "match_df = spark.read.format(\"csv\").option(\"header\", True).load(\"s3://ipl-data-analysis-project/Match.csv\")\n",
    "match_df.createOrReplaceTempView(\"match\")\n",
    "\n",
    "# Load team data\n",
    "team_df = spark.read.format(\"csv\").option(\"header\", True).load(\"s3://ipl-data-analysis-project/Team.csv\")\n",
    "team_df.createOrReplaceTempView(\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2afc9380-a421-4ea3-8027-26cb3a7f995d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register DataFrames as temp views\n",
    "\n",
    "team_df.createOrReplaceTempView(\"team\")\n",
    "match_df.createOrReplaceTempView(\"match\")\n",
    "\n",
    "# Example SQL query: total runs by batsman per team per match\n",
    "result_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  t.Team_Name,\n",
    "  COUNT(m.Match_SK) AS matches_played\n",
    "FROM\n",
    "  team t\n",
    "JOIN\n",
    "  match m\n",
    "ON\n",
    "  t.Team_Id = m.Team1 OR t.Team_Id = m.Team2\n",
    "GROUP BY\n",
    "  t.Team_Name\n",
    "ORDER BY\n",
    "  matches_played DESC\n",
    "\"\"\")\n",
    "display(result_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "IPL DATA ANALYSIS",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
